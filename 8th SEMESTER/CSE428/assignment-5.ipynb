{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94424aab",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e5d21f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Shadab Iqbal\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad29e19b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1bb0d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f327043ab1d7602159a6bba7bd99a12",
     "grade": false,
     "grade_id": "cell-a2e54225c26e0b98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this assignment you will have to create the VGG-19 network from scratch, using the keras functional API and explore its usage for different tasks. [(The Functional API).](https://www.tensorflow.org/guide/keras/functional)\n",
    "[Going through the *Setup* and *Introduction* sections of the previous tutorial will suffice if you haven't attended the live demo sessions.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eda193",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c841a63e919da083a88e1054ead6edbc",
     "grade": false,
     "grade_id": "cell-20efd04ba8ae4430",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 0 - Reading The Paper\n",
    "\n",
    "Read the VGG paper: [Very Deep Convolutional Networks for Large-Scale Image Recognition - Karen Simonyan, Andrew Zisserman](https://arxiv.org/abs/1409.1556) and complete the following tasks. This assignment is based on the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af358662",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "185225bf9e8dd6a7a95211790d94919d",
     "grade": false,
     "grade_id": "cell-5925ce5fb6c01a1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1\n",
    "\n",
    "Complete the following block to create a VGG19 network suitable for the ILSVRC classification task in keras and print the network's summary. (You don't have to train the network.)\n",
    "\n",
    "[Hint: __Section 2 CONVNET CONFIGURATIONS__ of the paper contains necessary information about the network architecture of the VGG network. (Column E of Table 1 is the VGG19 network architecture.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0b0972",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ade879d6b3ceb051898e7f89d42307e6",
     "grade": false,
     "grade_id": "cell-43a92f5124a74091",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383a2ed5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bf91d26a60980e9058770b4362996cd",
     "grade": true,
     "grade_id": "cell-d0f037183f3d3439",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "# REMOVE THE `raise NotImplementedError()` line first\n",
    "# your code should take the input layer, and process it to produce the output\n",
    "# as shown in the paper\n",
    "# YOUR CODE HERE\n",
    "x = layers.Conv2D(64, 3, activation = \"relu\", padding='same') (inputs)\n",
    "x = layers.Conv2D(64, 3, activation = \"relu\", padding='same') (x)\n",
    "\n",
    "x = layers.MaxPooling2D(2) (x)\n",
    "\n",
    "x = layers.Conv2D(128, 3, activation = \"relu\", padding='same') (x)\n",
    "x = layers.Conv2D(128, 3, activation = \"relu\", padding='same') (x)\n",
    "\n",
    "x = layers.MaxPooling2D(2) (x)\n",
    "\n",
    "x = layers.Conv2D(256, 3, activation = \"relu\", padding='same') (x)\n",
    "x = layers.Conv2D(256, 3, activation = \"relu\", padding='same') (x)\n",
    "x = layers.Conv2D(256, 3, activation = \"relu\", padding='same') (x)\n",
    "x = layers.Conv2D(256, 3, activation = \"relu\", padding='same') (x)\n",
    "\n",
    "x = layers.MaxPooling2D(2) (x)\n",
    "\n",
    "x = layers.Conv2D(512, 3, activation = \"relu\", padding='same') (x)\n",
    "x = layers.Conv2D(512, 3, activation = \"relu\", padding='same') (x)\n",
    "x = layers.Conv2D(512, 3, activation = \"relu\", padding='same') (x)\n",
    "x = layers.Conv2D(512, 3, activation = \"relu\", padding='same') (x)\n",
    "\n",
    "x = layers.MaxPooling2D(2) (x)\n",
    "\n",
    "x = layers.Conv2D(512, 3, activation = \"relu\", padding='same') (x)\n",
    "x = layers.Conv2D(512, 3, activation = \"relu\", padding='same') (x)\n",
    "x = layers.Conv2D(512, 3, activation = \"relu\", padding='same') (x)\n",
    "x = layers.Conv2D(512, 3, activation = \"relu\", padding='same') (x)\n",
    "\n",
    "x = layers.MaxPooling2D(2) (x)\n",
    "\n",
    "x = layers.Flatten() (x)\n",
    "\n",
    "x = layers.Dense(4096, activation='relu') (x)\n",
    "x = layers.Dense(4096, activation='relu') (x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1000, activation=\"softmax\") (x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"vgg19\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff47139",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07216e2f5a9ffcc1438cfa778c37e21d",
     "grade": false,
     "grade_id": "cell-3ed0d014f91ce105",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Your summary should match the following:\n",
    "```\n",
    "Model: \"vgg19\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
    "_________________________________________________________________\n",
    "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
    "_________________________________________________________________\n",
    "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
    "_________________________________________________________________\n",
    "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
    "_________________________________________________________________\n",
    "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
    "_________________________________________________________________\n",
    "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
    "_________________________________________________________________\n",
    "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
    "_________________________________________________________________\n",
    "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
    "_________________________________________________________________\n",
    "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
    "_________________________________________________________________\n",
    "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
    "_________________________________________________________________\n",
    "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
    "_________________________________________________________________\n",
    "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 25088)             0         \n",
    "_________________________________________________________________\n",
    "fc1 (Dense)                  (None, 4096)              102764544 \n",
    "_________________________________________________________________\n",
    "fc2 (Dense)                  (None, 4096)              16781312  \n",
    "_________________________________________________________________\n",
    "predictions (Dense)          (None, 1000)              4097000   \n",
    "=================================================================\n",
    "Total params: 143,667,240\n",
    "Trainable params: 143,667,240\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919bd2c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b54351c5c05fcb0681667e62969521e4",
     "grade": false,
     "grade_id": "cell-b1b8a6ade6b2335d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 1\n",
    "\n",
    "What percentage of total parameters are in the fully connected layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea58d8a7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c505cbb9e72f0e14abb9301bbc1d8729",
     "grade": true,
     "grade_id": "cell-46633e7c6c996750",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "86.06% parameters are in the fully connected layers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc22c84f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af3cc4f5540dd7ae5eb177f4514d279d",
     "grade": false,
     "grade_id": "cell-a6c2c32f428aa116",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "The VGG19 network from task 1 contains a Dense (FC) output layer with 1000 units for the ILSVRC classification task. How could you modify the current output layer so that it is capable of classifying the CIFAR-100 dataset, which has a total number of 100 classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934fb1b6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "606c79c3d71d77978889502b2b716b8d",
     "grade": true,
     "grade_id": "cell-4398a605b898adab",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "We just have to change the line \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1000, activation=\"softmax\") (x) \n",
    "\n",
    "to \n",
    "\n",
    "outputs = tf.keras.layers.Dense(100, activation=\"softmax\") (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001fc736",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9dd783329ccffd570d063b4f612727bf",
     "grade": false,
     "grade_id": "cell-6d9f27c84eacdeeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 3\n",
    "\n",
    "The VGG19 network from task 1 was designed for the ILSVRC classification challenge, but as we know there was a seperate challenge for image localisation. How could you modify the current ouput layer so that is suitable for the ILSVRC localisation task?\n",
    "\n",
    "[Hint: __Section A LOCALISATION__ contains information about the localisation task.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d46bb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3317a178b442ca5a8c86d62541bd3a10",
     "grade": true,
     "grade_id": "cell-6772494888bc296e",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "We can modify the current outpout layer by making the last fully connected layer to predict the bounding box location instead of the class scores. That is how we can change the classification task to localisation task. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b1d0c1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7dd599bc0144d358581e1d157040b57a",
     "grade": false,
     "grade_id": "cell-1207b3000d2654c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 4\n",
    "\n",
    "The VGG19 network from task 1 was designed for the ILSVRC classification challenge. Explain how the authors proposed this deep network as a feature extractor for other computer vision tasks.\n",
    "[Hint: __B GENERALISATION OF VERY DEEP FEATURES__ contains information about using the VGG network as a feature extractor.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc58204",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ecf7f601f99a8ec01b5d0b935ad19fe",
     "grade": true,
     "grade_id": "cell-301566000184a295",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "The authors first rescaled an image so that its smallest side equals Q, and then they applied the network densely over the image plane. Then they performed global average pooling on the resulting feature map, which produced a 4096-D image descriptor. After that they averaged the descriptor with the descriptor of a horizontally flipped image. They figured out that evaluation over multiple scales is beneficial, so they extracted features over several scales Q. The resulting multi-scale features could either be stacked or pooled across scales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
